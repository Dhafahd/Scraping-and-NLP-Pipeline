{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ca727c-a49d-435c-8bfd-6cbeac391a01",
   "metadata": {},
   "source": [
    "### PART II : Using NLP Pipeline on one Arabic article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792cf89a-788c-4e72-b7c9-5cee89c2b7c5",
   "metadata": {},
   "source": [
    "#### I - Scrap the article :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6457bfdc-a06d-4193-91ad-f49150b5c029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'الاسكوا: الاحتلال وحالات الصراع عائق كبير أمام التنمية المستدامة في المنطقة العربية'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "url = 'https://aljarida24.ma/p/actualites/271314/'\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(page.text, 'html')\n",
    "\n",
    "para_div=soup.find('div',{'class':'content-text'})\n",
    "\n",
    "header = soup.find('h1').text.strip()\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59fc9650-8310-48a4-b571-57ff0700acbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ذكرت اللجنة الاقتصادية والاجتماعية لغربي آسيا (الإسكوا)، أن الاحتلال وحالات الصراع وعدم الاستقرار في عدد من الدول العربية تشكل عائقا كبير جدا أمام تحقيق أهداف التنمية المستدامة في المنطقة العربية.  وأوضحت المسؤولة بمجموعة تنسيق العمل على خطة 2030 وأهـداف التنمية المستدامة في الإسكوا، جنى البابا، أن هذه العوامل تحول دون تحقيق الاهداف التنموية المرجوة في تسع بلدان عربية تضم حوالي 40 بالمائة من سكان المنطقة العربية، مع ما لذلك من تأثير على المنطقة بأسرها.  وقالت المسؤولة الأممية في تصريحات أوردتها صحف عربية اليوم الخميس إن هناك عدة عوامل تضع البلدان العربية التي تعاني من النزاعات \"في حلقة مفرغة\" لا تستطيع الخروج منها بسهولة، وتجعلها غير قادرة على استعادة مسار التنمية، الأمر الذي يؤثر على أجيال كثيرة وليس فقط على الجيل الحاضر.  وسجلت أن هناك قاسمين مشتركين أساسيين في مختلف حالات الدول التي تعاني من الصراعات في المنطقة أو من تداعياتها، هي قضية النزوح واللجوء، حيث يوجد في المنطقة حوالي 9 ملايين لاجئ يعيشون في ظروف صعبة، ويؤثرون كذلك على الفئات أو المجتمعات التي تستضيفهم، علاوة على 19 مليون نازح داخلي.  وأضافت أن القاسم المشترك الثاني الذي تعاني منه تلك الدول بسبب الصراعات، هو انهيار المؤسسات \"لأن هذه الحروب التي يستمر أكثرها لعقد أو أكثر، أضعفت قدرة المؤسسات العامة وأفرغتها من الكفاءات ومن قدرتها على تقديم الخدمات العامة من بينها التعليم والصحة وأيضا الأمن على كامل أراضيها\".  وذكرت أن \"تحديات مثل تلك التي تواجهها المنطقة العربية تكشف انه \"لا يمكن أن تكون هناك تنمية مستدامة بدون سلام\"، مشددة على أنه \"مهما كانت الصعوبات تبقى خطة 2030 وأهدافها هي البوصلة وخارطة الطريق نحو مستقبل أفضل للأجيال الحالية والأجيال المقبلة\".  \n"
     ]
    }
   ],
   "source": [
    "# Initialiser une variable pour stocker tous les paragraphes\n",
    "all_paragraphs = \"\"\n",
    "\n",
    "# Parcourir le contenu de para_div et concaténer les textes des paragraphes\n",
    "for item in para_div.contents:\n",
    "    if item.name == 'p':\n",
    "        all_paragraphs += item.text.strip() + \"  \"\n",
    "\n",
    "# Maintenant, all_paragraphs contient le texte de tous les paragraphes avec des espaces entre eux\n",
    "print(all_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcafb7d6-7fd8-41d6-87f0-37ed1509bc1f",
   "metadata": {},
   "source": [
    "#### II - Establishment of NLP Pipeline (Text Cleaning, Tokenization, Stop words, Discretization, Normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15200d34-40ad-4c6f-b1eb-9a24bc993c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity Cleaner: Unites entity tags and fixs misspellings \n",
    "def tags_cleaner(entity):\n",
    "  entity = re.sub('\\n','',entity) # Remove the newline (\\n)\n",
    "  if entity in ['B-LOC', 'B-MIS', 'B-ORG','B-PER','I-LOC','I-MIS','I-ORG','I-PER','O']:\n",
    "    return entity\n",
    "  elif entity in ['B-MIS0','B-MIS1', 'B-MIS2', 'B-MIS3', 'B-MIS-1','B-MIS-2', 'B-MIS1`', 'B-MISS1']:\n",
    "    return 'B-MIS'\n",
    "  elif entity in ['I-MIS0','I-MIS1', 'I-MIS2', 'I-MIS3']:\n",
    "    return 'I-MIS'\n",
    "  elif entity in ['B-ENGLISH', 'B-SPANISH', 'OO', 'IO']:\n",
    "    return 'O'\n",
    "  elif entity == 'I--ORG':\n",
    "    return 'I-ORG'\n",
    "  else:\n",
    "    print('Error with entity:', entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0823fc-08c4-43d4-8176-8be5257e3bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ذكرت اللجنة الاقتصادية والاجتماعية لغربي آسيا (الإسكوا)، أن الاحتلال وحالات الصراع وعدم الاستقرار في عدد من الدول العربية تشكل عائقا كبير جدا أمام تحقيق أهداف التنمية المستدامة في المنطقة العربية.  وأوضحت المسؤولة بمجموعة تنسيق العمل على خطة 2030 وأهـداف التنمية المستدامة في الإسكوا، جنى البابا، أن هذه العوامل تحول دون تحقيق الاهداف التنموية المرجوة في تسع بلدان عربية تضم حوالي 40 بالمائة من سكان المنطقة العربية، مع ما لذلك من تأثير على المنطقة بأسرها.  وقالت المسؤولة الأممية في تصريحات أوردتها صحف عربية اليوم الخميس إن هناك عدة عوامل تضع البلدان العربية التي تعاني من النزاعات \"في حلقة مفرغة\" لا تستطيع الخروج منها بسهولة، وتجعلها غير قادرة على استعادة مسار التنمية، الأمر الذي يؤثر على أجيال كثيرة وليس فقط على الجيل الحاضر.  وسجلت أن هناك قاسمين مشتركين أساسيين في مختلف حالات الدول التي تعاني من الصراعات في المنطقة أو من تداعياتها، هي قضية النزوح واللجوء، حيث يوجد في المنطقة حوالي 9 ملايين لاجئ يعيشون في ظروف صعبة، ويؤثرون كذلك على الفئات أو المجتمعات التي تستضيفهم، علاوة على 19 مليون نازح داخلي.  وأضافت أن القاسم المشترك الثاني الذي تعاني منه تلك الدول بسبب الصراعات، هو انهيار المؤسسات \"لأن هذه الحروب التي يستمر أكثرها لعقد أو أكثر، أضعفت قدرة المؤسسات العامة وأفرغتها من الكفاءات ومن قدرتها على تقديم الخدمات العامة من بينها التعليم والصحة وأيضا الأمن على كامل أراضيها\".  وذكرت أن \"تحديات مثل تلك التي تواجهها المنطقة العربية تكشف انه \"لا يمكن أن تكون هناك تنمية مستدامة بدون سلام\"، مشددة على أنه \"مهما كانت الصعوبات تبقى خطة 2030 وأهدافها هي البوصلة وخارطة الطريق نحو مستقبل أفضل للأجيال الحالية والأجيال المقبلة\".  \n",
      "-----------------------------------------------------------\n",
      "ذكرت اللجنه الاقتصاديه والاجتماعيه لغربي اسيا الاسكوا ان الاحتلال وحالات الصراع وعدم الاستقرار في عدد من الدول العربيه تشكل عائقا كبير جدا امام تحقيق اهداف التنميه المستدامه في المنطقه العربيه  واوضحت المسؤوله بمجموعه تنسيق العمل علي خطه 2030 واهداف التنميه المستدامه في الاسكوا جني البابا ان هذه العوامل تحول دون تحقيق الاهداف التنمويه المرجوه في تسع بلدان عربيه تضم حوالي 40 بالمائه من سكان المنطقه العربيه مع ما لذلك من تاثير علي المنطقه باسرها  وقالت المسؤوله الامميه في تصريحات اوردتها صحف عربيه اليوم الخميس ان هناك عده عوامل تضع البلدان العربيه التي تعاني من النزاعات في حلقه مفرغه لا تستطيع الخروج منها بسهوله وتجعلها غير قادره علي استعاده مسار التنميه الامر الذي يؤثر علي اجيال كثيره وليس فقط علي الجيل الحاضر  وسجلت ان هناك قاسمين مشتركين اساسين في مختلف حالات الدول التي تعاني من الصراعات في المنطقه او من تداعياتها هي قضيه النزوح واللجوء حيث يوجد في المنطقه حوالي 9 ملاين لاجئ يعيشون في ظروف صعبه ويؤثرون كذلك علي الفئات او المجتمعات التي تستضيفهم علاوه علي 19 مليون نازح داخلي  واضافت ان القاسم المشترك الثاني الذي تعاني منه تلك الدول بسبب الصراعات هو انهيار المؤسسات لان هذه الحروب التي يستمر اكثرها لعقد او اكثر اضعفت قدره المؤسسات العامه وافرغتها من الكفاءات ومن قدرتها علي تقديم الخدمات العامه من بينها التعليم والصحه وايضا الامن علي كامل اراضيها  وذكرت ان تحديات مثل تلك التي تواجهها المنطقه العربيه تكشف انه لا يمكن ان تكون هناك تنميه مستدامه بدون سلام مشدده علي انه مهما كانت الصعوبات تبقي خطه 2030 واهدافها هي البوصله وخارطه الطريق نحو مستقبل افضل للاجيال الحاليه والاجيال المقبله\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_10344\\790905078.py:10: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  url = re.compile('https?://\\S+|www\\.S+')\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_10344\\790905078.py:14: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  email = re.compile('[A-Za-z0-2]+@[\\w]+.[\\w]+')\n"
     ]
    }
   ],
   "source": [
    "# Clean/Normalize Arabic Text\n",
    "def clean_str(text):\n",
    "    search = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",'\"',\"ـ\",\"'\",\"ى\",'\\n', '\\t','\"','?','؟','!']\n",
    "    replace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\"\",\"\",\"\",\"ي\",\"\",' ', ' ',' ',' ? ',' ؟ ',' ! ']\n",
    "    # remove HTML TAG\n",
    "    html = re.compile('[<،,()\"\".#*?>]')\n",
    "    text = html.sub(r'',text)\n",
    "    \n",
    "    # Remove urls:\n",
    "    url = re.compile('https?://\\S+|www\\.S+')\n",
    "    text = url.sub(r'',text)\n",
    "    \n",
    "    # Remove email id:\n",
    "    email = re.compile('[A-Za-z0-2]+@[\\w]+.[\\w]+')\n",
    "    text = email.sub(r'',text)\n",
    "    \n",
    "    # Remove tashkeel\n",
    "    p_tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
    "    text = re.sub(p_tashkeel,\"\", text)\n",
    "    \n",
    "    # Remove longation \"EX : سلاممممم = سلامم\"\n",
    "    p_longation = re.compile(r'(.)\\1+')\n",
    "    subst = r\"\\1\\1\"\n",
    "    text = re.sub(p_longation, subst, text)\n",
    "    \n",
    "    text = text.replace('وو', 'و')\n",
    "    text = text.replace('يي', 'ي')\n",
    "    text = text.replace('اا', 'ا')\n",
    "\n",
    "    for i in range(0, len(search)):\n",
    "        text = text.replace(search[i], replace[i])\n",
    "    \n",
    "    # remove any leading and trailing whitespace characters    \n",
    "    text = text.strip()\n",
    "    return text\n",
    "    \n",
    "print(all_paragraphs)\n",
    "print(\"-----------------------------------------------------------\")\n",
    "para = clean_str(all_paragraphs)\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e7b436-f16d-4e9d-8704-bc7cddd722d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(para):\n",
    " # Tokenize the text\n",
    " tokens = word_tokenize(para)\n",
    "\n",
    " # Filter tokens to keep only non-numeric ones\n",
    " filtered_tokens = [token for token in tokens if not token.isdigit()]\n",
    "\n",
    " # Regular expression pattern to match words starting with 'و'\n",
    " pattern = r'^و\\w*'\n",
    "    \n",
    " # Tokenize the words starting with 'و'\n",
    " custom_tokens = []\n",
    " for token in filtered_tokens:\n",
    "    if re.match(pattern, token):\n",
    "        custom_tokens.append('و')\n",
    "        if len(token) > 1:\n",
    "            custom_tokens.append(token[1:])\n",
    "    else:\n",
    "        custom_tokens.append(token)\n",
    " return custom_tokens\n",
    "\n",
    "custom_tokens=tokenize(para)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4941b43-6275-4675-b1e8-3df563e4237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens:\n",
      "['ذكرت', 'اللجنه', 'الاقتصاديه', 'و', 'الاجتماعيه', 'لغربي', 'اسيا', 'الاسكوا', 'ان', 'الاحتلال', 'و', 'حالات', 'الصراع', 'و', 'عدم', 'الاستقرار', 'في', 'عدد', 'من', 'الدول', 'العربيه', 'تشكل', 'عائقا', 'كبير', 'جدا', 'امام', 'تحقيق', 'اهداف', 'التنميه', 'المستدامه', 'في', 'المنطقه', 'العربيه', 'و', 'اوضحت', 'المسؤوله', 'بمجموعه', 'تنسيق', 'العمل', 'علي', 'خطه', 'و', 'اهداف', 'التنميه', 'المستدامه', 'في', 'الاسكوا', 'جني', 'البابا', 'ان', 'هذه', 'العوامل', 'تحول', 'دون', 'تحقيق', 'الاهداف', 'التنمويه', 'المرجوه', 'في', 'تسع', 'بلدان', 'عربيه', 'تضم', 'حوالي', 'بالمائه', 'من', 'سكان', 'المنطقه', 'العربيه', 'مع', 'ما', 'لذلك', 'من', 'تاثير', 'علي', 'المنطقه', 'باسرها', 'و', 'قالت', 'المسؤوله', 'الامميه', 'في', 'تصريحات', 'اوردتها', 'صحف', 'عربيه', 'اليوم', 'الخميس', 'ان', 'هناك', 'عده', 'عوامل', 'تضع', 'البلدان', 'العربيه', 'التي', 'تعاني', 'من', 'النزاعات', 'في', 'حلقه', 'مفرغه', 'لا', 'تستطيع', 'الخروج', 'منها', 'بسهوله', 'و', 'تجعلها', 'غير', 'قادره', 'علي', 'استعاده', 'مسار', 'التنميه', 'الامر', 'الذي', 'يؤثر', 'علي', 'اجيال', 'كثيره', 'و', 'ليس', 'فقط', 'علي', 'الجيل', 'الحاضر', 'و', 'سجلت', 'ان', 'هناك', 'قاسمين', 'مشتركين', 'اساسين', 'في', 'مختلف', 'حالات', 'الدول', 'التي', 'تعاني', 'من', 'الصراعات', 'في', 'المنطقه', 'او', 'من', 'تداعياتها', 'هي', 'قضيه', 'النزوح', 'و', 'اللجوء', 'حيث', 'يوجد', 'في', 'المنطقه', 'حوالي', 'ملاين', 'لاجئ', 'يعيشون', 'في', 'ظروف', 'صعبه', 'و', 'يؤثرون', 'كذلك', 'علي', 'الفئات', 'او', 'المجتمعات', 'التي', 'تستضيفهم', 'علاوه', 'علي', 'مليون', 'نازح', 'داخلي', 'و', 'اضافت', 'ان', 'القاسم', 'المشترك', 'الثاني', 'الذي', 'تعاني', 'منه', 'تلك', 'الدول', 'بسبب', 'الصراعات', 'هو', 'انهيار', 'المؤسسات', 'لان', 'هذه', 'الحروب', 'التي', 'يستمر', 'اكثرها', 'لعقد', 'او', 'اكثر', 'اضعفت', 'قدره', 'المؤسسات', 'العامه', 'و', 'افرغتها', 'من', 'الكفاءات', 'و', 'من', 'قدرتها', 'علي', 'تقديم', 'الخدمات', 'العامه', 'من', 'بينها', 'التعليم', 'و', 'الصحه', 'و', 'ايضا', 'الامن', 'علي', 'كامل', 'اراضيها', 'و', 'ذكرت', 'ان', 'تحديات', 'مثل', 'تلك', 'التي', 'تواجهها', 'المنطقه', 'العربيه', 'تكشف', 'انه', 'لا', 'يمكن', 'ان', 'تكون', 'هناك', 'تنميه', 'مستدامه', 'بدون', 'سلام', 'مشدده', 'علي', 'انه', 'مهما', 'كانت', 'الصعوبات', 'تبقي', 'خطه', 'و', 'اهدافها', 'هي', 'البوصله', 'و', 'خارطه', 'الطريق', 'نحو', 'مستقبل', 'افضل', 'للاجيال', 'الحاليه', 'و', 'الاجيال', 'المقبله']\n",
      "\n",
      "Filtered Tokens:\n",
      "['ذكرت', 'اللجنه', 'الاقتصاديه', 'الاجتماعيه', 'لغربي', 'اسيا', 'الاسكوا', 'ان', 'الاحتلال', 'حالات', 'الصراع', 'عدم', 'الاستقرار', 'عدد', 'الدول', 'العربيه', 'تشكل', 'عائقا', 'كبير', 'جدا', 'امام', 'تحقيق', 'اهداف', 'التنميه', 'المستدامه', 'المنطقه', 'العربيه', 'اوضحت', 'المسؤوله', 'بمجموعه', 'تنسيق', 'العمل', 'علي', 'خطه', 'اهداف', 'التنميه', 'المستدامه', 'الاسكوا', 'جني', 'البابا', 'ان', 'العوامل', 'تحول', 'تحقيق', 'الاهداف', 'التنمويه', 'المرجوه', 'بلدان', 'عربيه', 'تضم', 'حوالي', 'بالمائه', 'سكان', 'المنطقه', 'العربيه', 'لذلك', 'تاثير', 'علي', 'المنطقه', 'باسرها', 'قالت', 'المسؤوله', 'الامميه', 'تصريحات', 'اوردتها', 'صحف', 'عربيه', 'اليوم', 'الخميس', 'ان', 'عده', 'عوامل', 'تضع', 'البلدان', 'العربيه', 'تعاني', 'النزاعات', 'حلقه', 'مفرغه', 'تستطيع', 'الخروج', 'بسهوله', 'تجعلها', 'قادره', 'علي', 'استعاده', 'مسار', 'التنميه', 'الامر', 'يؤثر', 'علي', 'اجيال', 'كثيره', 'فقط', 'علي', 'الجيل', 'الحاضر', 'سجلت', 'ان', 'قاسمين', 'مشتركين', 'اساسين', 'مختلف', 'حالات', 'الدول', 'تعاني', 'الصراعات', 'المنطقه', 'او', 'تداعياتها', 'قضيه', 'النزوح', 'اللجوء', 'يوجد', 'المنطقه', 'حوالي', 'ملاين', 'لاجئ', 'يعيشون', 'ظروف', 'صعبه', 'يؤثرون', 'علي', 'الفئات', 'او', 'المجتمعات', 'تستضيفهم', 'علاوه', 'علي', 'مليون', 'نازح', 'داخلي', 'اضافت', 'ان', 'القاسم', 'المشترك', 'الثاني', 'تعاني', 'الدول', 'بسبب', 'الصراعات', 'انهيار', 'المؤسسات', 'لان', 'الحروب', 'يستمر', 'اكثرها', 'لعقد', 'او', 'اكثر', 'اضعفت', 'قدره', 'المؤسسات', 'العامه', 'افرغتها', 'الكفاءات', 'قدرتها', 'علي', 'تقديم', 'الخدمات', 'العامه', 'بينها', 'التعليم', 'الصحه', 'ايضا', 'الامن', 'علي', 'كامل', 'اراضيها', 'ذكرت', 'ان', 'تحديات', 'تواجهها', 'المنطقه', 'العربيه', 'تكشف', 'انه', 'يمكن', 'ان', 'تكون', 'تنميه', 'مستدامه', 'بدون', 'سلام', 'مشدده', 'علي', 'انه', 'كانت', 'الصعوبات', 'تبقي', 'خطه', 'اهدافها', 'البوصله', 'خارطه', 'الطريق', 'مستقبل', 'افضل', 'للاجيال', 'الحاليه', 'الاجيال', 'المقبله']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def stop_words(custom_tokens):\n",
    " # Load Arabic stopwords\n",
    " stop_words = set(stopwords.words('arabic'))\n",
    "\n",
    " # Filter out stop words\n",
    " filtered_sentence = [token for token in custom_tokens if not token in stop_words]\n",
    " return filtered_sentence\n",
    "\n",
    "filtered_sentence= stop_words(custom_tokens)\n",
    "print(\"Original Tokens:\")\n",
    "print(custom_tokens)\n",
    "print(\"\\nFiltered Tokens:\")\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63daa0-0b47-44c0-8d62-fca239148e7c",
   "metadata": {},
   "source": [
    "#### III - Using the Stemming and Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af31b20-4bfd-4c7c-95bc-0f625eaa05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ISRIStemmer\n",
    "\n",
    "stemmer = ISRIStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in filtered_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90c9fd1-66c9-45c1-a616-e70ec9753aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 3.70MB/s]\n",
      "2024-04-08 02:01:18 INFO: Downloaded file to C:\\Users\\lenovo\\stanza_resources\\resources.json\n",
      "2024-04-08 02:01:18 INFO: Downloading default packages for language: ar (Arabic) ...\n",
      "2024-04-08 02:01:19 INFO: File exists: C:\\Users\\lenovo\\stanza_resources\\ar\\default.zip\n",
      "2024-04-08 02:01:23 INFO: Finished downloading models and saved to C:\\Users\\lenovo\\stanza_resources\n",
      "2024-04-08 02:01:23 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 2.95MB/s]\n",
      "2024-04-08 02:01:24 INFO: Downloaded file to C:\\Users\\lenovo\\stanza_resources\\resources.json\n",
      "2024-04-08 02:01:24 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-04-08 02:01:24 INFO: Loading these models for language: ar (Arabic):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | padt          |\n",
      "| mwt       | padt          |\n",
      "| pos       | padt_charlm   |\n",
      "| lemma     | padt_nocharlm |\n",
      "=============================\n",
      "\n",
      "2024-04-08 02:01:24 INFO: Using device: cpu\n",
      "2024-04-08 02:01:24 INFO: Loading: tokenize\n",
      "2024-04-08 02:01:27 INFO: Loading: mwt\n",
      "2024-04-08 02:01:27 INFO: Loading: pos\n",
      "2024-04-08 02:01:28 INFO: Loading: lemma\n",
      "2024-04-08 02:01:28 INFO: Done loading processors!\n",
      "2024-04-08 02:01:28 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 3.99MB/s]\n",
      "2024-04-08 02:01:29 INFO: Downloaded file to C:\\Users\\lenovo\\stanza_resources\\resources.json\n",
      "2024-04-08 02:01:29 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-04-08 02:01:30 INFO: Loading these models for language: ar (Arabic):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | padt          |\n",
      "| mwt       | padt          |\n",
      "| pos       | padt_charlm   |\n",
      "| lemma     | padt_nocharlm |\n",
      "=============================\n",
      "\n",
      "2024-04-08 02:01:30 INFO: Using device: cpu\n",
      "2024-04-08 02:01:30 INFO: Loading: tokenize\n",
      "2024-04-08 02:01:30 INFO: Loading: mwt\n",
      "2024-04-08 02:01:30 INFO: Loading: pos\n",
      "2024-04-08 02:01:30 INFO: Loading: lemma\n",
      "2024-04-08 02:01:30 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_sentence:\n",
      "['ذكرت', 'اللجنه', 'الاقتصاديه', 'الاجتماعيه', 'لغربي', 'اسيا', 'الاسكوا', 'ان', 'الاحتلال', 'حالات', 'الصراع', 'عدم', 'الاستقرار', 'عدد', 'الدول', 'العربيه', 'تشكل', 'عائقا', 'كبير', 'جدا', 'امام', 'تحقيق', 'اهداف', 'التنميه', 'المستدامه', 'المنطقه', 'العربيه', 'اوضحت', 'المسؤوله', 'بمجموعه', 'تنسيق', 'العمل', 'علي', 'خطه', 'اهداف', 'التنميه', 'المستدامه', 'الاسكوا', 'جني', 'البابا', 'ان', 'العوامل', 'تحول', 'تحقيق', 'الاهداف', 'التنمويه', 'المرجوه', 'بلدان', 'عربيه', 'تضم', 'حوالي', 'بالمائه', 'سكان', 'المنطقه', 'العربيه', 'لذلك', 'تاثير', 'علي', 'المنطقه', 'باسرها', 'قالت', 'المسؤوله', 'الامميه', 'تصريحات', 'اوردتها', 'صحف', 'عربيه', 'اليوم', 'الخميس', 'ان', 'عده', 'عوامل', 'تضع', 'البلدان', 'العربيه', 'تعاني', 'النزاعات', 'حلقه', 'مفرغه', 'تستطيع', 'الخروج', 'بسهوله', 'تجعلها', 'قادره', 'علي', 'استعاده', 'مسار', 'التنميه', 'الامر', 'يؤثر', 'علي', 'اجيال', 'كثيره', 'فقط', 'علي', 'الجيل', 'الحاضر', 'سجلت', 'ان', 'قاسمين', 'مشتركين', 'اساسين', 'مختلف', 'حالات', 'الدول', 'تعاني', 'الصراعات', 'المنطقه', 'او', 'تداعياتها', 'قضيه', 'النزوح', 'اللجوء', 'يوجد', 'المنطقه', 'حوالي', 'ملاين', 'لاجئ', 'يعيشون', 'ظروف', 'صعبه', 'يؤثرون', 'علي', 'الفئات', 'او', 'المجتمعات', 'تستضيفهم', 'علاوه', 'علي', 'مليون', 'نازح', 'داخلي', 'اضافت', 'ان', 'القاسم', 'المشترك', 'الثاني', 'تعاني', 'الدول', 'بسبب', 'الصراعات', 'انهيار', 'المؤسسات', 'لان', 'الحروب', 'يستمر', 'اكثرها', 'لعقد', 'او', 'اكثر', 'اضعفت', 'قدره', 'المؤسسات', 'العامه', 'افرغتها', 'الكفاءات', 'قدرتها', 'علي', 'تقديم', 'الخدمات', 'العامه', 'بينها', 'التعليم', 'الصحه', 'ايضا', 'الامن', 'علي', 'كامل', 'اراضيها', 'ذكرت', 'ان', 'تحديات', 'تواجهها', 'المنطقه', 'العربيه', 'تكشف', 'انه', 'يمكن', 'ان', 'تكون', 'تنميه', 'مستدامه', 'بدون', 'سلام', 'مشدده', 'علي', 'انه', 'كانت', 'الصعوبات', 'تبقي', 'خطه', 'اهدافها', 'البوصله', 'خارطه', 'الطريق', 'مستقبل', 'افضل', 'للاجيال', 'الحاليه', 'الاجيال', 'المقبله']\n",
      "\n",
      "Lemmatized Tokens:\n",
      "['ذَكَر', 'لَجنَه', 'اِقتِصَادِيّ', 'اِجتِمَاعِيّ', 'لِ', 'غَربِيّ', 'آسِيَا', 'الاسكوا', 'أَنَّ', 'اِحتِلَال', 'حَالَة', 'صِرَاع', 'عَدَم', 'اِستِقرَار', 'عَدَد', 'دَولَة', 'عَرَبِيّ', 'شَكَّل', 'عَائِق', 'كَبِير', 'جِدّ', 'أَمَامَ', 'تَحقِيق', 'هَدَف', 'التنميه', 'مُستَدَام', 'هُوَ', 'المنطقه', 'عَرَبِيّ', 'أَوضَح', 'مَسؤُول', 'بِ', 'مَجمُوع', 'هُوَ', 'تَنسِيق', 'عَمَل', 'عَلَى', 'خُطَّة', 'هَدَف', 'التنميه', 'مُستَدَام', 'هُوَ', 'الاسكوا', 'جني', 'البابا', 'أَنَّ', 'عَامِل', 'تَحَوَّل', 'تَحقِيق', 'هَدَف', 'التنمويه', 'مَرجُوه', 'بِ', 'لِدَان', 'عَرَبِيّ', 'هُوَ', 'ضَمّ', 'حَوَالَى', 'بِ', 'مَاءِه', 'سَاكِن', 'مُنطَقَه', 'عَرَبِيّ', 'لِ', 'ذٰلِكَ', 'تَاثِير', 'عَلَى', 'مُنطَقَه', 'بَاسِر', 'هُوَ', 'قَال', 'مَسؤُول', 'أَممِيه', 'تَصرِيح', 'أَورَد', 'هُوَ', 'صَحِيفَة', 'عَرَبِيّ', 'هُوَ', 'يَوم', 'خَمِيس', 'أَنَّ', 'عَدَه', 'عَامِل', 'وَضَع', 'بَلَد', 'عَرَبِيّ', 'عَانَى', 'نِزَاع', 'حَلِيقَة', 'هُوَ', 'مُفَرَّغ', 'هُوَ', 'اِستَطَاع', 'خُرُوج', 'بِ', 'سُهُول', 'هُوَ', 'جَعَل', 'هُوَ', 'قَادِر', 'هُوَ', 'عَلَى', 'اِستِعَاد', 'هُوَ', 'مَسَار', 'تَنمِيه', 'أَمر', 'أَثَّر', 'عَلَى', 'جَيل', 'كَثِير', 'هُوَ', 'فَقَط', 'عَلَى', 'جِيل', 'حَاضِر', 'سَجَّل', 'أَنَّ', 'قَاسِم', 'مُشتَرَك', 'أَسَاس', 'مُختَلِف', 'حَالَة', 'دَولَة', 'عَانَى', 'صِرَاع', 'المنطقه', 'أَو', 'تَدَاعِي', 'هُوَ', 'قَضي', 'هُوَ', 'نُزُوح', 'لُجُوء', 'وَجَد', 'مُنطَقَه', 'حَوَالَى', 'مِليُو', 'لاجئ', 'عَاش', 'ظَرف', 'صَعب', 'هُوَ', 'أَثَّر', 'عَلَى', 'فِئَة', 'أَو', 'مُجتَمَع', 'اِستَضَاف', 'هُوَ', 'عَلَا', 'هُوَ', 'عَلَى', 'مِليُون', 'نَازِح', 'دَاخِلِيّ', 'أَضَاف', 'أَنَّ', 'القاسم', 'مُشتَرَك', 'ثَانِي', 'عَانَى', 'دَولَة', 'بِ', 'سَبَب', 'صِرَاع', 'اِنهِيَار', 'مُؤَسَّسَة', 'لِأَنَّ', 'حَرب', 'اِستَمَرّ', 'أَكثَر', 'هُوَ', 'لِ', 'عَقد', 'أَو', 'أَكثَر', 'أَضعَف', 'قَدر', 'هُوَ', 'مُؤَسَّسَة', 'عَامِه', 'أَفرَغ', 'هُوَ', 'كَفَاءَة', 'قُدرَة', 'هُوَ', 'عَلَى', 'تَقدِيم', 'خِدمَة', 'عَامِه', 'بَينَ', 'هُوَ', 'تَعلِيم', 'صَحه', 'أَيضًا', 'أَمن', 'عَلَى', 'كَامِل', 'أَرض', 'هُوَ', 'ذَكَر', 'أَنَّ', 'تَحَدِّي', 'وَاجَه', 'هُوَ', 'مُنطَقَه', 'عَرَبِيّ', 'كَشَف', 'أَنَّ', 'هُوَ', 'أَمكَن', 'أَنَّ', 'كَان', 'تَنَمِّي', 'هُوَ', 'مُستَدَام', 'هُوَ', 'بِ', 'دُونَ', 'سَلَام', 'مُشَدَّد', 'هُوَ', 'عَلَى', 'أَنَّ', 'هُوَ', 'كَان', 'صُعُوبَة', 'أَبقَى', 'خُطَّة', 'إِهدَاف', 'هُوَ', 'البوصله', 'خَارِط', 'هُوَ', 'طَرِيق', 'مُستَقبَل', 'افضل', 'لِ', 'جِيل', 'حَالِيّ', 'جِيل', 'مُقبِل']\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Download Arabic resources for Stanza\n",
    "stanza.download('ar')\n",
    "\n",
    "# Initialize Stanza pipeline for Arabic\n",
    "nlp = stanza.Pipeline('ar', processors='tokenize,pos,lemma')\n",
    "\n",
    "# Join tokenized words into a single string\n",
    "arabic_text = ' '.join(filtered_sentence)\n",
    "\n",
    "# Initialize Stanza pipeline for Arabic\n",
    "nlp = stanza.Pipeline('ar', processors='tokenize,pos,lemma')\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(arabic_text)\n",
    "\n",
    "# Extract lemmas\n",
    "lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "\n",
    "print(\"filtered_sentence:\")\n",
    "print(filtered_sentence)\n",
    "print(\"\\nLemmatized Tokens:\")\n",
    "print(lemmas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76238771-2811-44fd-84f5-1593ee615219",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = ' '.join(lemmas)\n",
    "lemmas=clean_str(lemmas)\n",
    "lemmas=tokenize(lemmas)\n",
    "lemmas= stop_words(custom_tokens)\n",
    "lemmas1 = ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1981eb79-919e-481a-8fae-44baf394c1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ذكرت', 'ADJ'), ('اللجنه', 'NOUN'), ('الاقتصاديه', 'NOUN'), ('الاجتماعيه', 'NOUN'), ('لغربي', 'NOUN'), ('اسيا', 'NOUN'), ('الاسكوا', 'NOUN'), ('ان', 'NOUN'), ('الاحتلال', 'NOUN'), ('حالات', 'NOUN'), ('الصراع', 'NOUN'), ('عدم', 'NOUN'), ('الاستقرار', 'NOUN'), ('عدد', 'NOUN'), ('الدول', 'NOUN'), ('العربيه', 'NOUN'), ('تشكل', 'NOUN'), ('عائقا', 'NOUN'), ('كبير', 'NOUN'), ('جدا', 'NOUN'), ('امام', 'NOUN'), ('تحقيق', 'NOUN'), ('اهداف', 'NOUN'), ('التنميه', 'NOUN'), ('المستدامه', 'NOUN'), ('المنطقه', 'NOUN'), ('العربيه', 'NOUN'), ('اوضحت', 'NOUN'), ('المسؤوله', 'NOUN'), ('بمجموعه', 'NOUN'), ('تنسيق', 'NOUN'), ('العمل', 'NOUN'), ('علي', 'NOUN'), ('خطه', 'NOUN'), ('اهداف', 'NOUN'), ('التنميه', 'NOUN'), ('المستدامه', 'NOUN'), ('الاسكوا', 'NOUN'), ('جني', 'NOUN'), ('البابا', 'NOUN'), ('ان', 'NOUN'), ('العوامل', 'NOUN'), ('تحول', 'NOUN'), ('تحقيق', 'NOUN'), ('الاهداف', 'NOUN'), ('التنمويه', 'NOUN'), ('المرجوه', 'NOUN'), ('بلدان', 'NOUN'), ('عربيه', 'NOUN'), ('تضم', 'NOUN'), ('حوالي', 'NOUN'), ('بالمائه', 'NOUN'), ('سكان', 'NOUN'), ('المنطقه', 'NOUN'), ('العربيه', 'NOUN'), ('لذلك', 'NOUN'), ('تاثير', 'NOUN'), ('علي', 'NOUN'), ('المنطقه', 'NOUN'), ('باسرها', 'NOUN'), ('قالت', 'NOUN'), ('المسؤوله', 'NOUN'), ('الامميه', 'NOUN'), ('تصريحات', 'NOUN'), ('اوردتها', 'NOUN'), ('صحف', 'NOUN'), ('عربيه', 'NOUN'), ('اليوم', 'NOUN'), ('الخميس', 'NOUN'), ('ان', 'NOUN'), ('عده', 'NOUN'), ('عوامل', 'NOUN'), ('تضع', 'NOUN'), ('البلدان', 'NOUN'), ('العربيه', 'NOUN'), ('تعاني', 'NOUN'), ('النزاعات', 'NOUN'), ('حلقه', 'NOUN'), ('مفرغه', 'NOUN'), ('تستطيع', 'NOUN'), ('الخروج', 'NOUN'), ('بسهوله', 'NOUN'), ('تجعلها', 'NOUN'), ('قادره', 'NOUN'), ('علي', 'NOUN'), ('استعاده', 'NOUN'), ('مسار', 'NOUN'), ('التنميه', 'NOUN'), ('الامر', 'NOUN'), ('يؤثر', 'NOUN'), ('علي', 'NOUN'), ('اجيال', 'NOUN'), ('كثيره', 'NOUN'), ('فقط', 'NOUN'), ('علي', 'NOUN'), ('الجيل', 'NOUN'), ('الحاضر', 'NOUN'), ('سجلت', 'NOUN'), ('ان', 'NOUN'), ('قاسمين', 'NOUN'), ('مشتركين', 'NOUN'), ('اساسين', 'NOUN'), ('مختلف', 'NOUN'), ('حالات', 'NOUN'), ('الدول', 'NOUN'), ('تعاني', 'NOUN'), ('الصراعات', 'NOUN'), ('المنطقه', 'NOUN'), ('او', 'NOUN'), ('تداعياتها', 'NOUN'), ('قضيه', 'NOUN'), ('النزوح', 'NOUN'), ('اللجوء', 'NOUN'), ('يوجد', 'NOUN'), ('المنطقه', 'NOUN'), ('حوالي', 'NOUN'), ('ملاين', 'NOUN'), ('لاجئ', 'NOUN'), ('يعيشون', 'NOUN'), ('ظروف', 'NOUN'), ('صعبه', 'NOUN'), ('يؤثرون', 'NOUN'), ('علي', 'NOUN'), ('الفئات', 'NOUN'), ('او', 'NOUN'), ('المجتمعات', 'NOUN'), ('تستضيفهم', 'NOUN'), ('علاوه', 'NOUN'), ('علي', 'NOUN'), ('مليون', 'NOUN'), ('نازح', 'NOUN'), ('داخلي', 'NOUN'), ('اضافت', 'NOUN'), ('ان', 'NOUN'), ('القاسم', 'NOUN'), ('المشترك', 'NOUN'), ('الثاني', 'NOUN'), ('تعاني', 'NOUN'), ('الدول', 'NOUN'), ('بسبب', 'NOUN'), ('الصراعات', 'NOUN'), ('انهيار', 'NOUN'), ('المؤسسات', 'NOUN'), ('لان', 'NOUN'), ('الحروب', 'NOUN'), ('يستمر', 'NOUN'), ('اكثرها', 'NOUN'), ('لعقد', 'NOUN'), ('او', 'NOUN'), ('اكثر', 'NOUN'), ('اضعفت', 'NOUN'), ('قدره', 'NOUN'), ('المؤسسات', 'NOUN'), ('العامه', 'NOUN'), ('افرغتها', 'NOUN'), ('الكفاءات', 'NOUN'), ('قدرتها', 'NOUN'), ('علي', 'NOUN'), ('تقديم', 'NOUN'), ('الخدمات', 'NOUN'), ('العامه', 'NOUN'), ('بينها', 'NOUN'), ('التعليم', 'NOUN'), ('الصحه', 'NOUN'), ('ايضا', 'NOUN'), ('الامن', 'NOUN'), ('علي', 'NOUN'), ('كامل', 'NOUN'), ('اراضيها', 'NOUN'), ('ذكرت', 'NOUN'), ('ان', 'NOUN'), ('تحديات', 'NOUN'), ('تواجهها', 'NOUN'), ('المنطقه', 'NOUN'), ('العربيه', 'NOUN'), ('تكشف', 'NOUN'), ('انه', 'NOUN'), ('يمكن', 'NOUN'), ('ان', 'NOUN'), ('تكون', 'NOUN'), ('تنميه', 'NOUN'), ('مستدامه', 'NOUN'), ('بدون', 'NOUN'), ('سلام', 'NOUN'), ('مشدده', 'NOUN'), ('علي', 'NOUN'), ('انه', 'NOUN'), ('كانت', 'NOUN'), ('الصعوبات', 'NOUN'), ('تبقي', 'NOUN'), ('خطه', 'NOUN'), ('اهدافها', 'NOUN'), ('البوصله', 'NOUN'), ('خارطه', 'NOUN'), ('الطريق', 'NOUN'), ('مستقبل', 'NOUN'), ('افضل', 'NOUN'), ('للاجيال', 'NOUN'), ('الحاليه', 'NOUN'), ('الاجيال', 'NOUN'), ('المقبله', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('universal_tagset')\n",
    "pos=nltk.pos_tag(lemmas,tagset='universal')\n",
    "# Print the tagged text\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1b3a6-5e33-4b8d-b145-f888912d73ce",
   "metadata": {},
   "source": [
    "### IV - Comparetion of the tow mechanisms (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5b750-2acf-4e8e-bc2f-703ea3e9dfdd",
   "metadata": {},
   "source": [
    "Stemming and lemmatization are text preprocessing techniques in natural language processing (NLP). Specifically, they reduce the inflected forms of words\n",
    "across a text data set to one common root word or dictionary form, also known as a “lemma” in computational linguistics.\n",
    "Stemming and lemmatization are particularly helpful in information retrieval systems like search engines where users may submit a query with one word\n",
    "(for example, meditate) but expect results that use any inflected form of the word (for example, meditates, meditation, etc.). \n",
    "Although they are identical, the choice depends on the situation and objectives. In our situation, lemmatization is more effective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a9c19-b820-4ab7-ac9c-fdd4187606f6",
   "metadata": {},
   "source": [
    "### V- Parts of Speech technics based on both Rule based and Machine learning approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "251c6afe-e23f-4f33-afe5-83cea6a187b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 2.46MB/s]\n",
      "2024-04-08 02:01:35 INFO: Downloaded file to C:\\Users\\lenovo\\stanza_resources\\resources.json\n",
      "2024-04-08 02:01:35 INFO: Downloading default packages for language: ar (Arabic) ...\n",
      "2024-04-08 02:01:36 INFO: File exists: C:\\Users\\lenovo\\stanza_resources\\ar\\default.zip\n",
      "2024-04-08 02:01:40 INFO: Finished downloading models and saved to C:\\Users\\lenovo\\stanza_resources\n",
      "2024-04-08 02:01:40 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 3.42MB/s]\n",
      "2024-04-08 02:01:41 INFO: Downloaded file to C:\\Users\\lenovo\\stanza_resources\\resources.json\n",
      "2024-04-08 02:01:43 INFO: Loading these models for language: ar (Arabic):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | padt          |\n",
      "| mwt       | padt          |\n",
      "| pos       | padt_charlm   |\n",
      "| lemma     | padt_nocharlm |\n",
      "| depparse  | padt_charlm   |\n",
      "| ner       | aqmar_charlm  |\n",
      "=============================\n",
      "\n",
      "2024-04-08 02:01:43 INFO: Using device: cpu\n",
      "2024-04-08 02:01:43 INFO: Loading: tokenize\n",
      "2024-04-08 02:01:43 INFO: Loading: mwt\n",
      "2024-04-08 02:01:43 INFO: Loading: pos\n",
      "2024-04-08 02:01:43 INFO: Loading: lemma\n",
      "2024-04-08 02:01:43 INFO: Loading: depparse\n",
      "2024-04-08 02:01:44 INFO: Loading: ner\n",
      "2024-04-08 02:01:45 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ذكرت', 'VERB'), ('اللجنه', 'NOUN'), ('الاقتصاديه', 'ADJ'), ('الاجتماعيه', 'ADJ'), ('ل', 'ADP'), ('غربي', 'ADJ'), ('اسيا', 'X'), ('الاسكوا', 'X'), ('ان', 'SCONJ'), ('الاحتلال', 'NOUN'), ('حالات', 'NOUN'), ('الصراع', 'NOUN'), ('عدم', 'NOUN'), ('الاستقرار', 'NOUN'), ('عدد', 'NOUN'), ('الدول', 'NOUN'), ('العربيه', 'ADJ'), ('تشكل', 'VERB'), ('عائقا', 'NOUN'), ('كبير', 'ADJ'), ('جدا', 'NOUN'), ('امام', 'ADP'), ('تحقيق', 'NOUN'), ('اهداف', 'NOUN'), ('التنميه', 'X'), ('المستدام', 'ADJ'), ('ه', 'PRON'), ('المنطقه', 'X'), ('العربيه', 'ADJ'), ('اوضحت', 'VERB'), ('المسؤوله', 'NOUN'), ('ب', 'ADP'), ('مجموع', 'ADJ'), ('ه', 'PRON'), ('تنسيق', 'NOUN'), ('العمل', 'NOUN'), ('علي', 'ADP'), ('خطه', 'NOUN'), ('اهداف', 'X'), ('التنميه', 'X'), ('المستدام', 'ADJ'), ('ه', 'PRON'), ('الاسكوا', 'X'), ('جني', 'X'), ('البابا', 'X'), ('ان', 'SCONJ'), ('العوامل', 'NOUN'), ('تحول', 'VERB'), ('تحقيق', 'NOUN'), ('الاهداف', 'NOUN'), ('التنمويه', 'X'), ('المرجوه', 'ADJ'), ('ب', 'ADP'), ('لدان', 'NOUN'), ('عربي', 'ADJ'), ('ه', 'PRON'), ('تضم', 'VERB'), ('حوالي', 'ADP'), ('ب', 'ADP'), ('الماءه', 'NOUN'), ('سكان', 'NOUN'), ('المنطقه', 'NOUN'), ('العربيه', 'ADJ'), ('ل', 'ADP'), ('ذٰلك', 'DET'), ('تاثير', 'NOUN'), ('علي', 'ADP'), ('المنطقه', 'NOUN'), ('باسر', 'ADJ'), ('ها', 'PRON'), ('قالت', 'VERB'), ('المسؤوله', 'NOUN'), ('الامميه', 'ADJ'), ('تصريحات', 'NOUN'), ('أوردت', 'VERB'), ('ها', 'PRON'), ('صحف', 'NOUN'), ('عربي', 'ADJ'), ('ه', 'PRON'), ('اليوم', 'NOUN'), ('الخميس', 'NOUN'), ('ان', 'SCONJ'), ('عده', 'NOUN'), ('عوامل', 'NOUN'), ('تضع', 'VERB'), ('البلدان', 'NOUN'), ('العربيه', 'ADJ'), ('تعاني', 'VERB'), ('النزاعات', 'NOUN'), ('حلق', 'NOUN'), ('ه', 'PRON'), ('مفرغ', 'ADJ'), ('ه', 'PRON'), ('تستطيع', 'VERB'), ('الخروج', 'NOUN'), ('ب', 'ADP'), ('سهول', 'NOUN'), ('ه', 'PRON'), ('تجعل', 'VERB'), ('ها', 'PRON'), ('قادر', 'ADJ'), ('ه', 'PRON'), ('علي', 'ADP'), ('استعاد', 'NOUN'), ('ه', 'PRON'), ('مسار', 'NOUN'), ('التنميه', 'NOUN'), ('الامر', 'NOUN'), ('يؤثر', 'VERB'), ('علي', 'ADP'), ('اجيال', 'NOUN'), ('كثير', 'ADJ'), ('ه', 'PRON'), ('فقط', 'ADV'), ('علي', 'ADP'), ('الجيل', 'NOUN'), ('الحاضر', 'ADJ'), ('سجلت', 'VERB'), ('ان', 'SCONJ'), ('قاسمين', 'NOUN'), ('مشتركين', 'ADJ'), ('اساسين', 'ADJ'), ('مختلف', 'ADJ'), ('حالات', 'NOUN'), ('الدول', 'NOUN'), ('تعاني', 'VERB'), ('الصراعات', 'NOUN'), ('المنطقه', 'X'), ('او', 'CCONJ'), ('تداعيات', 'NOUN'), ('ها', 'PRON'), ('قضي', 'NOUN'), ('ه', 'PRON'), ('النزوح', 'NOUN'), ('اللجوء', 'NOUN'), ('يوجد', 'VERB'), ('المنطقه', 'NOUN'), ('حوالي', 'ADP'), ('ملاين', 'NUM'), ('لاجئ', 'X'), ('يعيشون', 'VERB'), ('ظروف', 'NOUN'), ('صعب', 'NOUN'), ('ه', 'PRON'), ('يؤثرون', 'VERB'), ('علي', 'ADP'), ('الفئات', 'NOUN'), ('او', 'CCONJ'), ('المجتمعات', 'NOUN'), ('تستضيف', 'VERB'), ('هم', 'PRON'), ('علاوا', 'VERB'), ('ه', 'PRON'), ('علي', 'ADP'), ('مليون', 'NUM'), ('نازح', 'NOUN'), ('داخلي', 'ADJ'), ('اضافت', 'VERB'), ('ان', 'SCONJ'), ('القاسم', 'X'), ('المشترك', 'ADJ'), ('الثاني', 'ADJ'), ('تعاني', 'VERB'), ('الدول', 'NOUN'), ('ب', 'ADP'), ('سبب', 'NOUN'), ('الصراعات', 'NOUN'), ('انهيار', 'NOUN'), ('المؤسسات', 'NOUN'), ('لان', 'CCONJ'), ('الحروب', 'NOUN'), ('يستمر', 'VERB'), ('أكثر', 'ADJ'), ('ها', 'PRON'), ('ل', 'ADP'), ('عقد', 'NOUN'), ('او', 'CCONJ'), ('اكثر', 'ADJ'), ('اضعفت', 'VERB'), ('قدر', 'NOUN'), ('ه', 'PRON'), ('المؤسسات', 'NOUN'), ('العامه', 'ADJ'), ('أفرغت', 'VERB'), ('ها', 'PRON'), ('الكفاءات', 'NOUN'), ('قدرة', 'NOUN'), ('ها', 'PRON'), ('علي', 'ADP'), ('تقديم', 'NOUN'), ('الخدمات', 'NOUN'), ('العامه', 'ADJ'), ('بين', 'ADP'), ('ها', 'PRON'), ('التعليم', 'NOUN'), ('الصحه', 'NOUN'), ('ايضا', 'ADV'), ('الامن', 'NOUN'), ('علي', 'ADP'), ('كامل', 'ADJ'), ('أراضي', 'NOUN'), ('ها', 'PRON'), ('ذكرت', 'VERB'), ('ان', 'SCONJ'), ('تحديات', 'NOUN'), ('تواجه', 'VERB'), ('ها', 'PRON'), ('المنطقه', 'NOUN'), ('العربيه', 'ADJ'), ('تكشف', 'VERB'), ('أن', 'SCONJ'), ('ه', 'PRON'), ('يمكن', 'VERB'), ('ان', 'SCONJ'), ('تكون', 'VERB'), ('تنمي', 'NOUN'), ('ه', 'PRON'), ('مستدام', 'NOUN'), ('ه', 'PRON'), ('ب', 'ADP'), ('دون', 'ADP'), ('سلام', 'NOUN'), ('مشدد', 'ADJ'), ('ه', 'PRON'), ('علي', 'ADP'), ('أن', 'SCONJ'), ('ه', 'PRON'), ('كانت', 'VERB'), ('الصعوبات', 'NOUN'), ('تبقي', 'VERB'), ('خطه', 'NOUN'), ('إهداف', 'NOUN'), ('ها', 'PRON'), ('البوصله', 'X'), ('خارط', 'NOUN'), ('ه', 'PRON'), ('الطريق', 'NOUN'), ('مستقبل', 'NOUN'), ('افضل', 'X'), ('ل', 'ADP'), ('الأجيال', 'NOUN'), ('الحاليه', 'ADJ'), ('الاجيال', 'X'), ('المقبله', 'ADJ')]\n"
     ]
    }
   ],
   "source": [
    "# Download and load the Arabic model\n",
    "stanza.download('ar')  # Download the Arabic model\n",
    "nlp = stanza.Pipeline('ar')  # Load the Arabic model\n",
    "\n",
    "# Process the text and obtain POS tags\n",
    "doc = nlp(lemmas1)\n",
    "\n",
    "# Extract POS tags\n",
    "pos_tags = []\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        pos_tags.append((word.text, word.upos))\n",
    "\n",
    "# Print POS tags\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74bef9-36b1-4060-9a97-dd85a6f25534",
   "metadata": {},
   "source": [
    "### VI - NER Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70326761-d5b8-493c-a38c-65a4522c7222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named entity recognized:\n",
      " ذكرت/O اللجنه/B-ORG الاقتصاديه/I-ORG الاجتماعيه/I-ORG لغربي/I-ORG اسيا/I-ORG الاسكوا/O ان/O الاحتلال/O حالات/O الصراع/O عدم/O الاستقرار/O عدد/O الدول/O العربيه/O تشكل/O عائقا/O كبير/O جدا/O امام/O تحقيق/O اهداف/O التنميه/O المستدامه/O المنطقه/O العربيه/O اوضحت/O المسؤوله/O بمجموعه/O تنسيق/O العمل/O علي/O خطه/O اهداف/O التنميه/O المستدامه/O الاسكوا/O جني/O البابا/B-PERS ان/O العوامل/O تحول/O تحقيق/O الاهداف/O التنمويه/O المرجوه/O بلدان/O عربيه/O تضم/O حوالي/O بالمائه/O سكان/O المنطقه/B-LOC العربيه/I-LOC لذلك/O تاثير/O علي/O المنطقه/O باسرها/O قالت/O المسؤوله/O الامميه/O تصريحات/O اوردتها/O صحف/O عربيه/O اليوم/O الخميس/O ان/O عده/O عوامل/O تضع/O البلدان/O العربيه/O تعاني/O النزاعات/O حلقه/O مفرغه/O تستطيع/O الخروج/O بسهوله/O تجعلها/O قادره/O علي/O استعاده/O مسار/O التنميه/O الامر/O يؤثر/O علي/O اجيال/O كثيره/O فقط/O علي/O الجيل/O الحاضر/O سجلت/O ان/O قاسمين/O مشتركين/O اساسين/O مختلف/O حالات/O الدول/O تعاني/O الصراعات/O المنطقه/O او/O تداعياتها/O قضيه/O النزوح/O اللجوء/O يوجد/O المنطقه/O حوالي/O ملاين/O لاجئ/O يعيشون/O ظروف/O صعبه/O يؤثرون/O علي/O الفئات/O او/O المجتمعات/O تستضيفهم/O علاوه/O علي/O مليون/O نازح/O داخلي/O اضافت/O ان/O القاسم/O المشترك/O الثاني/O تعاني/O الدول/O بسبب/O الصراعات/O انهيار/O المؤسسات/O لان/O الحروب/O يستمر/O اكثرها/O لعقد/O او/O اكثر/O اضعفت/O قدره/O المؤسسات/O العامه/O افرغتها/O الكفاءات/O قدرتها/O علي/O تقديم/O الخدمات/O العامه/O بينها/O التعليم/O الصحه/O ايضا/O الامن/O علي/O كامل/O اراضيها/O ذكرت/O ان/O تحديات/O تواجهها/O المنطقه/O العربيه/O تكشف/O انه/O يمكن/O ان/O تكون/O تنميه/O مستدامه/O بدون/O سلام/O مشدده/O علي/O انه/O كانت/O الصعوبات/O تبقي/O خطه/O اهدافها/O البوصله/O خارطه/O الطريق/O مستقبل/O افضل/O للاجيال/O الحاليه/O الاجيال/O المقبله/O\n"
     ]
    }
   ],
   "source": [
    "from farasa.ner import FarasaNamedEntityRecognizer \n",
    "\n",
    "named_entity_recognizer = FarasaNamedEntityRecognizer()\n",
    "\n",
    "NamedEntityRecognized = named_entity_recognizer.recognize(lemmas1)\n",
    "print(\"Named entity recognized:\\n\", NamedEntityRecognized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788f5fb-a4d4-48ed-ac87-742e4b3e9f72",
   "metadata": {},
   "source": [
    "### VII : Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fecc3f9-5ccd-4b3a-b098-4fc4c77cf427",
   "metadata": {},
   "source": [
    "#### This first lab was a great opportunity to get familiar with the difference libraries of Scraping and  techniques of storing data in the database in addition of NLP Pipeline that we have seen in during class from Text Cleaning and Tokenization to Parts of Speech and NER Methods by using them in Arabic paragraph which was a bit difficult but we get to know this technologies more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c8b6c-f42d-48f3-95e5-527c4953e439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
